{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"gemma2:2b\", request_timeout=120.0, json_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"Translate the following text from Nepali to English:\\n\\n{text}\\n\\nTranslation:\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
    "]\n",
    "resp = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from typing import List\n",
    "\n",
    "def setup_translation_chat(\n",
    "    model_name: str = \"gemma2:2b\",\n",
    "    temperature: float = 0.7,\n",
    "    request_timeout: float = 120.0,\n",
    "    source_language: str = \"Nepali\",\n",
    "    target_language: str = \"English\"\n",
    ") -> tuple[Ollama, List[ChatMessage]]:\n",
    "    \"\"\"\n",
    "    Sets up an Ollama instance and chat messages for translation.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the Ollama model to use\n",
    "        temperature: Controls randomness in responses (0.0 to 1.0)\n",
    "        request_timeout: Maximum time to wait for response in seconds\n",
    "        source_language: Source language to translate from\n",
    "        target_language: Target language to translate to\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (Ollama instance, List of chat messages)\n",
    "    \"\"\"\n",
    "    # Initialize Ollama with proper configuration\n",
    "    llm = Ollama(\n",
    "        model=model_name,\n",
    "        temperature=temperature,\n",
    "        request_timeout=request_timeout,\n",
    "        # Use context_window if model supports it\n",
    "        context_window=4096,\n",
    "        # Additional parameters for better translation results\n",
    "        stop_sequences=[\"\\n\\n\"],\n",
    "        system_prompt=f\"You are a helpful translation assistant. Translate text from {source_language} to {target_language} accurately.\"\n",
    "    )\n",
    "    \n",
    "    # Create chat messages with clear translation instruction\n",
    "    messages = [\n",
    "        ChatMessage(\n",
    "            role=\"system\",\n",
    "            content=f\"Translate the following text from {source_language} to {target_language}:\\n\\n\" + \n",
    "                    \"{{text}}\\n\\n\" +\n",
    "                    f\"{target_language} translation:\"\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    return llm, messages\n",
    "\n",
    "def translate_text(text: str, llm: Ollama, messages: List[ChatMessage]) -> str:\n",
    "    \"\"\"\n",
    "    Translates text using the configured Ollama instance.\n",
    "    \n",
    "    Args:\n",
    "        text: Text to translate\n",
    "        llm: Configured Ollama instance\n",
    "        messages: Base chat messages\n",
    "    \n",
    "    Returns:\n",
    "        str: Translated text\n",
    "    \"\"\"\n",
    "    # Create a copy of base messages and add user message\n",
    "    translation_messages = messages.copy()\n",
    "    translation_messages.append(\n",
    "        ChatMessage(role=\"user\", content=text)\n",
    "    )\n",
    "    \n",
    "    # Get translation\n",
    "    response = llm.chat(translation_messages)\n",
    "    \n",
    "    return response.message.content\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: यही माघ १८ गतेदेखि सुरू हुने संघीय संसद्को हिउँदे अधिवेशनको कार्यतालिका तयार गरिएको छ । सभामुख देवराज घिमिरेको अध्यक्षतामा आज सिंहदरबारमा बसेको प्रमुख राजनीतिक दलका प्रमुख सचेतक र सचेतसहितको बैठकले माघ महिनाभरका लागि कार्यतालिका तयार गरेको हो ।\n",
      "Translation: The federal parliament's winter session schedule has been finalized. It commenced on the 18th of Magh and is set to begin, with a major political party heads meeting in Singhdarbar today. \n",
      "\n",
      "\n",
      "**English Translation:**\n",
      "\n",
      "The Federal Parliament’s winter session schedule has been finalized. It began on the 18th of Magh and will be commencing today at Singhdarbar, with a major political party head's meeting.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm, base_messages = setup_translation_chat()    \n",
    "nepali_text = \"यही माघ १८ गतेदेखि सुरू हुने संघीय संसद्को हिउँदे अधिवेशनको कार्यतालिका तयार गरिएको छ । सभामुख देवराज घिमिरेको अध्यक्षतामा आज सिंहदरबारमा बसेको प्रमुख राजनीतिक दलका प्रमुख सचेतक र सचेतसहितको बैठकले माघ महिनाभरका लागि कार्यतालिका तयार गरेको हो ।\"\n",
    "\n",
    "# Perform translation\n",
    "translation = translate_text(nepali_text, llm, base_messages)\n",
    "print(f\"Original: {nepali_text}\")\n",
    "print(f\"Translation: {translation}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: प्रधानमन्त्री केपी शर्मा ओलीले वित्तीय अपराध न्यूनीकरणका लागि सम्पत्ति शुद्धीकरण निवारण प्रणालीसँग सम्बन्धित निकायबीच समन्वयात्मक प्रयास अपरिहार्य भएको बताएका छन् ।\n",
      "Translation: The Prime Minister, KP Oli, has stated that collaborative efforts between concerned authorities for the mitigation of financial crime are imperative. \n",
      "\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "* **प्रधानमन्त्री केपी शर्मा ओली (Prime Minister KP Oli)**: This refers to the Nepali Prime Minister, K P Oli.  \n",
      "* **वित्तीय अपराध न्यूनीकरणका लागि सम्पत्ति शुद्धीकरण निवारण प्रणालीसँग सम्बन्धित निकायबीच समन्वयात्मक प्रयास (Financial Crime Mitigation through Asset Purification and Prevention System)**: This means that the Prime Minister has highlighted the need for collaborative efforts between institutions involved in asset purification to curb financial crimes.\n",
      "* **अपरिवार्य भएको बताएका छन् (Stated to be unavoidable):** The Prime Minister's statement indicates an urgent requirement for these collaborations. \n",
      "\n",
      "\n",
      "This translation captures the essence of the text. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nepali_text = \"प्रधानमन्त्री केपी शर्मा ओलीले वित्तीय अपराध न्यूनीकरणका लागि सम्पत्ति शुद्धीकरण निवारण प्रणालीसँग सम्बन्धित निकायबीच समन्वयात्मक प्रयास अपरिहार्य भएको बताएका छन् ।\"\n",
    "translation = translate_text(nepali_text, llm, base_messages)\n",
    "print(f\"Original: {nepali_text}\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
